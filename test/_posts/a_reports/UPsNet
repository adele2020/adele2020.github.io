UPSNet: A Unified Panoptic Segmentation Network

In this paper, we propose a unified panoptic segmentation network (UPSNet) for tackling the newly proposed panoptic segmentation task.
On top of a single backbone residual network, we first design a deformable convolution based semantic segmentation head and a Mask R-CNN style instance segmentation head which solve these two subtasks simultaneously.
More importantly, we introduce a parameter-free panoptic head which solves the panoptic segmentation via pixel-wise classification.
It first leverages the logits from the previous two heads and then innovatively expands the representation for enabling prediction of an extra unknown class which helps better resolve the conflicts between semantic and instance segmentation.
Additionally, it handles the challenge caused by the varying number of instances and permits back propagation to the bottom modules in an end-to-end manner.
Extensive experimental results on Cityscapes, COCO and our internal dataset demonstrate that our UPSNet achieves stateof-the-art performance with much faster inference.
Code has been made available at: https://github.com/uber-research/UPSNet.


이 논문에서는 새로 제안 된 panoptic 분할 작업을 해결하기위한 통합 panoptic 분할 네트워크 (UPSNet)를 제안합니다.
단일 백본 잔차 네트워크 위에 먼저 변형 가능한 컨볼 루션 기반 시맨틱 분할 헤드와이 두 하위 작업을 동시에 해결하는 Mask R-CNN 스타일 인스턴스 분할 헤드를 설계합니다.
더 중요한 것은 픽셀 단위 분류를 통해 파노라마 분할을 해결하는 매개 변수가없는 파노라마 헤드를 소개한다는 것입니다.
먼저 이전 두 헤드의 로짓을 활용 한 다음 의미론과 인스턴스 세분화 간의 충돌을 더 잘 해결하는 데 도움이되는 추가 알려지지 않은 클래스의 예측을 가능하게하기 위해 표현을 혁신적으로 확장합니다.
또한 다양한 인스턴스 수로 인해 발생하는 문제를 처리하고 종단 간 방식으로 하단 모듈로의 역 전파를 허용합니다.
Cityscapes, COCO 및 내부 데이터 세트에 대한 광범위한 실험 결과는 UPSNet이 훨씬 빠른 추론으로 최첨단 성능을 달성했음을 보여줍니다.
코드는 https://github.com/uber-research/UPSNet에서 사용할 수 있습니다.
